#!/usr/bin/env python3 

import argparse
import cv2
import errno
import itertools
import git
import os
import simplejson
import datetime
import re

import pathos.multiprocessing as mp
import numpy as np
import subprocess as sub
import AntarcticaUtils as a

import logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

RESULTS_FILENAME = 'results.csv'
RESULTS_IMAGE_DIRNAME = 'stitched_images'

#assert(not git.Repo(search_parent_directories=True).is_dirty()) # GIT REPO IS DITRY!
CSV_COMMENT_LINES = ['creation_time: '+str(datetime.datetime.now())] #,
#                     'code_version: ' + str(git.Repo(search_parent_directories=True).head.object.hexsha)]

OUTPUT_IMAGE_FILENAME_FORMAT = '{}_{}_{}-reel_begin_end.{}'
OUTPUT_FORMAT = '{reel_num},{begin_image_num},{end_image_num},{horizontal_flip},{vertical_flip},{high_res_filename},{low_res_filename},{status},{top_line},{top_line_y1},{top_line_y2},{top_line_num_groups},{bot_line},{bot_line_y1},{bot_line_y2},{bot_line_num_groups},{date},{time1},{time2},{setting},{flight},{cbd1},{cbd2},{cbd1_fractional},{cbd2_fractional},{num_additional_columns}'

OUTPUT_SMALL_IMAGE_FACTOR = 1/3.16227766017 # 1/sqrt(10)

class image_processer:

    SUCCESS = '0_success'
    COULD_NOT_PARSE_IMAGE_FILENAME = '1_malformed_image_filename'
    COULD_NOT_READ_IMAGE = '3_image_read_error'
    COULD_NOT_STITCH_FILM = '4_image_stitch_error'
    COULD_NOT_ORIENT_FILM = '5_image_orientation_error'
    COULD_NOT_FIND_TEXT = '6_image_find_text_error'
    COULD_NOT_PARSE_TEXT = '7_image_parse_text_error'
    COULD_NOT_WRITE_STITCHED_IMAGE = '8_could_not_write_stitched_image'
    
    def __init__(self, reel_num, output_dir):
        self.ocr_reader = a.BasicOCRReader()
        self.output_dir = output_dir
        self.reel_num = reel_num
        self.count = 0
        
    def get_filename_num(self, filename):
        return filename.split('-')[0].split('_')

    def noop(self, image_data, reason):
        logger.critical('FAILURE: {} {}'.format(image_data['min'], image_data['max']))
        logger.debug('performing noop for images because of: {}'.format(reason))

        image_path = image_data['image_path']

        d = {
            'reel_num' : self.reel_num,
            'begin_image_num' : image_data['min'],
            'end_image_num' : image_data['max'],
            'horizontal_flip' : '',
            'vertical_flip' : '',
            'high_res_filename' : '',
            'low_res_filename' : '',
            'status' : reason,
            'top_line' : image_data['top_line'],
            'top_line_y1' : image_data['top_line_y1'],
            'top_line_y2' : image_data['top_line_y2'],
            'top_line_num_groups' : image_data['top_line_num_groups'],
            'bot_line' : image_data['bot_line'],
            'bot_line_y1' : image_data['bot_line_y1'],
            'bot_line_y2' : image_data['bot_line_y2'],
            'bot_line_num_groups' : image_data['bot_line_num_groups'],
            'date' : '',
            'time1' : '',
            'time2' : '',
            'setting' : '',
            'flight' : '', 
            'cbd1' : '', 
            'cbd2' : '', 
            'cbd1_fractional' : '',
            'cbd2_fractional' : '',
            'num_additional_columns' : '0'
        }

        if reason in [image_processer.COULD_NOT_PARSE_IMAGE_FILENAME, image_processer.COULD_NOT_READ_IMAGE]:
            assert False, 'fatal error: could not read {}'.format(image_data['image_path'])
            return

        elif reason not in [image_processer.COULD_NOT_PARSE_IMAGE_FILENAME]:
            im = image_data['raster']

            d['horizontal_flip'] = image_data['horizontal_flip']
            d['vertical_flip'] = image_data['vertical_flip']
            d['num_additional_columns'] = len(image_data['text_detections'][0]) + len(image_data['text_detections'][1])
            
            if im is None:
                lines.append(OUTPUT_FORMAT.format(**d))
                
            tiff_filename = os.path.join(self.output_dir, RESULTS_IMAGE_DIRNAME, OUTPUT_IMAGE_FILENAME_FORMAT.format(self.reel_num, str(image_data['min']).zfill(7), str(image_data['max']).zfill(7), 'tiff'))
            jpg_filename = os.path.join(self.output_dir, RESULTS_IMAGE_DIRNAME, OUTPUT_IMAGE_FILENAME_FORMAT.format(self.reel_num, str(image_data['min']).zfill(7), str(image_data['max']).zfill(7), 'jpg'))
        
            ret = sub.check_call(['cp', '--reflink', image_data['image_path'], tiff_filename])
            if ret != 0:
                logger.debug('Could not process {}. Adding partial noop line'.format(image))
                lines.append(OUTPUT_FORMAT.format(**d))
            d['high_res_filename'] = tiff_filename

            image_labelled = a.BasicOCRReader.annotate_image_digits(im, image_data['text_detections'][0]+image_data['text_detections'][1], logger)            
            im_small = cv2.resize(image_labelled, None, fx=OUTPUT_SMALL_IMAGE_FACTOR, fy=OUTPUT_SMALL_IMAGE_FACTOR, interpolation = cv2.INTER_CUBIC)
            im_small = (im_small * (255 / 65535.0)).astype(np.uint8)

            ret = cv2.imwrite(jpg_filename, im_small)        
            if not ret:
                logger.debug('Could not process {}. Adding partial noop line'.format(image))
                lines.append(OUTPUT_FORMAT.format(**d))
            d['low_res_filename'] = jpg_filename

            line = OUTPUT_FORMAT.format(**d)
            dumps = lambda x : ',"' + simplejson.dumps(x,sort_keys=True).replace('"', "'").strip() + '"'
            for char_detection in image_data['text_detections'][0] + image_data['text_detections'][1]:
                del char_detection['x1']
                del char_detection['x2']
                del char_detection['y1']
                del char_detection['y2']
                del char_detection['segment']
                line += dumps(char_detection)
            
            return [line]

        else:
            assert False, 'this should never run!'
       
        
    def __call__(self, image_path):

        logger.debug('processing images in reel {}'.format(self.reel_num))

        image_data = {
            'image_path' : image_path,
            'reel' : None,
            'min' : None,
            'max' : None,
            'raster' : None
        }
            
        try:
            image_path_basename = os.path.basename(image_path)
            image_reel, image_min, image_max = self.get_filename_num(image_path_basename)
        except:
            logger.error('input filename is malformed; could not parse image number')
            return self.noop(image_path, image_processer.COULD_NOT_PARSE_IMAGE_FILENAME)

        image_data['reel'] = int(image_reel)
        image_data['min'] = int(image_min)
        image_data['max'] = int(image_max)
        logger.debug('Created metadata store')
        logger.debug('processing range {} - {}'.format(image_data['min'], image_data['max']))

        ########################################################################
        # attempt to open the image and associated metadata
        ########################################################################
        image_raster = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)

        if image_raster is None:
            logger.warning('Could not open {}. Skipping batch!'.format(image_path))
            return self.noop(image_data, image_processer.COULD_NOT_READ_IMAGE)

        image_data['raster'] = image_raster
        logger.debug('Loaded image')

        with open(image_path+'.csv', 'r') as f:
            r = re.compile(r'(?:[^,(\[]|\[[^\]]*\])+')
            data_elements = r.findall(f.read())
            preprocessing_metadata = {
                'flip_x': eval(data_elements[0]),
                'flip_y': eval(data_elements[1]),
                'top_line' : eval(data_elements[2]),
                'top_line_y' : eval(data_elements[3]),
                'top_num_groups' : eval(data_elements[4]),
                'bot_line' : eval(data_elements[5]),
                'bot_line_y' : eval(data_elements[6]),
                'bot_num_groups' : eval(data_elements[7]),
            }

        image_data['horizontal_flip'] = preprocessing_metadata['flip_x']
        image_data['vertical_flip'] = preprocessing_metadata['flip_y']

        image_data['top_line'] = preprocessing_metadata['top_line']
        if image_data['top_line']:
            image_data['top_line_y1'] = preprocessing_metadata['top_line_y'][0]
            image_data['top_line_y2'] = preprocessing_metadata['top_line_y'][1]
            image_data['top_line_num_groups'] = preprocessing_metadata['top_num_groups']
        else:
            image_data['top_line_y1'] = '' 
            image_data['top_line_y2'] = '' 
            image_data['top_line_num_groups'] = ''
            
        image_data['bot_line'] = preprocessing_metadata['bot_line']
        if image_data['bot_line']:
            image_data['bot_line_y1'] = preprocessing_metadata['bot_line_y'][0]
            image_data['bot_line_y2'] = preprocessing_metadata['bot_line_y'][1]
            image_data['bot_line_num_groups'] = preprocessing_metadata['bot_num_groups']
        else:
            image_data['bot_line_y1'] = '' 
            image_data['bot_line_y2'] = '' 
            image_data['bot_line_num_groups'] = ''


        ########################################################################
        # perform OCR
        ########################################################################
        logger.debug('Performing OCR')
        metadata = None
        number_groups = None
        image_data['text_detections'] = ([], [])
                
        text_detections = None
        #text_detections = self.ocr_reader.find_text(image_data['raster'], preprocessing_metadata, logger)
        try:
            text_detections = self.ocr_reader.find_text(image_data['raster'], preprocessing_metadata, logger)
        except:
            pass

        if text_detections is None:
            logger.warning('Could not find text on the stitched film strip. Skipping batch!')
            return self.noop(image_data, image_processer.COULD_NOT_FIND_TEXT)

        image_data['text_detections'] = text_detections
        logger.debug('Finished detecting text in the image')        
    
        ########################################################################
        # check that the recognized text is sensible and interpret it
        ########################################################################
        logger.debug('Performing interpretation')
        interpretation = None
        #interpretation = self.ocr_reader._interpret_text(text_detections, image_data['raster'].shape, logger)
        try:
            interpretation = self.ocr_reader._interpret_text(text_detections, image_data['raster'].shape, logger)
        except:
            pass

        if interpretation is None:
            logger.warning('Could not interpret text on the stitched film strip. Skipping batch!')
            return self.noop(image_data, image_processer.COULD_NOT_PARSE_TEXT)
            
        metadata, number_groups = interpretation

        assert image_data['horizontal_flip'] == preprocessing_metadata['flip_x']
        assert image_data['vertical_flip'] == preprocessing_metadata['flip_y']
        metadata['horizontal_flip'] = image_data['horizontal_flip']
        metadata['vertical_flip'] = image_data['vertical_flip']
        metadata['top_line'] = image_data['top_line']
        metadata['top_line_y1'] = image_data['top_line_y1']
        metadata['top_line_y2'] = image_data['top_line_y2']
        metadata['top_line_num_groups'] = image_data['top_line_num_groups']
        metadata['bot_line'] = image_data['bot_line']
        metadata['bot_line_y1'] = image_data['bot_line_y1']
        metadata['bot_line_y2'] = image_data['bot_line_y2']
        metadata['bot_line_num_groups'] = image_data['bot_line_num_groups']

        ########################################################################
        # dump annotated jpeg file and copy the tiff file
        ########################################################################
        tiff_filename = os.path.join(self.output_dir, RESULTS_IMAGE_DIRNAME, OUTPUT_IMAGE_FILENAME_FORMAT.format(self.reel_num, str(image_data['min']).zfill(7), str(image_data['max']).zfill(7), 'tiff'))
        jpg_filename = os.path.join(self.output_dir, RESULTS_IMAGE_DIRNAME, OUTPUT_IMAGE_FILENAME_FORMAT.format(self.reel_num, str(image_data['min']).zfill(7), str(image_data['max']).zfill(7), 'jpg'))

        ret = sub.check_call(['cp', '--reflink', image_path, tiff_filename])
        if ret != 0:
            logger.warning('Could not write tiff output to disk (ret={}); skipping batch!'.format(ret))
            return self.noop(image_data, image_processer.COULD_NOT_WRITE_STITCHED_IMAGE)

        image_labelled = a.BasicOCRReader.annotate_image(image_data['raster'], number_groups, logger)
        image_small = cv2.resize(image_labelled, None, fx=OUTPUT_SMALL_IMAGE_FACTOR, fy=OUTPUT_SMALL_IMAGE_FACTOR, interpolation = cv2.INTER_CUBIC)
        image_small = (image_small * (255 / 65535.0)).astype(np.uint8)
        ret = cv2.imwrite(jpg_filename, image_small)
        if not ret:
            logger.warning('Could not write jpg output to disk (ret={}); skipping batch!'.format(ret))
            return self.noop(image_data, image_processer.COULD_NOT_WRITE_STITCHED_IMAGE)

        logger.debug('Finished writing the stitched image to disk')
        
        # report the csv-formated line(s) that should be logged
        metadata['reel_num'] = self.reel_num
        metadata['begin_image_num'] = image_data['min']
        metadata['end_image_num'] = image_data['max']

        metadata['high_res_filename'] = tiff_filename
        metadata['low_res_filename'] = jpg_filename

        metadata['status'] = image_processer.SUCCESS

        metadata['num_additional_columns'] = len(number_groups) + len(text_detections[0]) + len(text_detections[1])
        line = OUTPUT_FORMAT.format(**metadata)

        # add supplementary information to the line (text detections and positions)
        dumps = lambda x : ',"' + simplejson.dumps(x,sort_keys=True).replace('"', "'").strip() + '"'
        for number_group in number_groups:
            line += dumps(number_group)

        for char_detection in text_detections[0] + text_detections[1]:
            del char_detection['x1']
            del char_detection['x2']
            del char_detection['y1']
            del char_detection['y2']
            del char_detection['segment']
            line += dumps(char_detection)

        logger.critical('SUCCESS: {} {}'.format(image_data['min'], image_data['max']))
            
        return [line]
            
def main(args):

    logger.info('Using {} worker(s)'.format(args.num_workers))
    pool = mp.Pool(args.num_workers)

    logger.debug('Checking if {} exists'.format(args.output_dir))
    try:
        os.makedirs(args.output_dir)
    except OSError as e:
        if e.errno != errno.EEXIST:
            logger.error('{} already exists!'.format(args.output_dir))
            return 
        else:
            raise e

    args.output_csv = os.path.join(args.output_dir, RESULTS_FILENAME)
    args.output_image_dir = os.path.join(args.output_dir, RESULTS_IMAGE_DIRNAME)
    os.makedirs(args.output_image_dir)
        
    logger.debug('Checking if {} exists'.format(args.output_csv))
    with open(args.output_csv, 'x') as f:
        for line in CSV_COMMENT_LINES:
            f.write('# ' + line.strip() + '\n')

        header = OUTPUT_FORMAT.replace('{', '').replace('}', '').strip()
        f.write(header+'\n')
        
    logger.info('Initialization completed')
    logger.debug('Preparing macro batches for processing')    
    if args.flush_interval is -1:
        macro_batches = [args.images]
    elif args.flush_interval is 0:
        logger.error('0 is not a valid flush interval (use -1 to disable flushing)')
    else:
        macro_batch_size = args.flush_interval * args.num_workers
        macro_batches = []
        for i in range(0, len(args.images), macro_batch_size):
            macro_batches.append(args.images[i:i+macro_batch_size])
            
    logger.info('Batches preapred (begin processing)')
    logger.debug('Processing data in %d batch(es)' % len(macro_batches))
    logger.debug('Begin processing batch(es)')
    for macro_batch in macro_batches:
        batches = []
        for i in range(len(macro_batch)):
            batches.append(macro_batch[i])

        CSVrows = itertools.chain.from_iterable(
            pool.map(image_processer(args.reel_num, args.output_dir), batches)
            #map(image_processer(args.reel_num, args.output_dir), batches)
        )
        
        with open(args.output_csv, 'a') as f:
            f.write('\n'.join(CSVrows)+'\n')

        logger.debug('Completed a macro batch')

    pool.close()
    pool.join()
    logger.debug('Finished processing batch(es)')
    logger.info('Done!')
        
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Perform OCR on radiometric data from Antarctic glaciers.')

    parser.add_argument('--parallel',
                        dest='num_workers',
                        metavar='num_workers',
                        type=int,
                        help='num worker processes to use (default: num cores on machine)',
                        default=os.cpu_count())

    parser.add_argument('--reel',
                        dest='reel_num',
                        metavar='reel_num',
                        type=str,
                        help='the reel number to use in the csv output')

    parser.add_argument('--flush',
                        dest='flush_interval',
                        metavar='flush_interval',
                        type=int,
                        help='number of batches to process before flushing results to output.csv (default: flush every batch); to disable flushing pass -1',
                        default=1)

    parser.add_argument('--output',
                        dest='output_dir',
                        metavar='output_dir',
                        type=str,
                        help='the directory to output processed images and CSV results')

    parser.add_argument(dest='images',
                        metavar='image',
                        type=str,
                        nargs='+',
                        help='images to process (NOTE: processed in the order they appear)')

    args = parser.parse_args()
        
    main(args)
