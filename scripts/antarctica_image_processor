#!/usr/bin/env python3

import argparse
import cv2
import errno
import itertools
import os

import pathos.multiprocessing as mp
import AntarcticaUtils as a

import logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# number of frames to stitch together
BATCH_SIZE = 25
RESULTS_FILENAME = 'results.csv'

class image_processer:

    INCORRECT_NUM_IMAGES = 0
    COULD_NOT_READ_IMAGE = 1
    COULD_NOT_STITCH_FILM = 2
    COULD_NOT_ORIENT_FILM = 3
    COULD_NOT_FIND_TEXT = 4
    
    def __init__(self):

        self.film_stitcther = a.BasicFilmstripStitcher(logger)
        self.ocr_reader = a.BasicOCRReader(logger)
        
    def get_filename_num(self, filename):
        return filename.split('_')[-1].split('.')[0]

    def noop(self, image_data, reason):
        # TODO(jremmons) write out image files
        # log the error in the CSV file
        return ''
        
    def __call__(self, images):

        image_data = {'nums' : [], 'min' : None, 'max' : None, 'rasters' : []}
        for image in images:
            num = self.get_filename_num(image)
            image_data['nums'].append(num)

        range_min = min(image_data['nums'])
        range_max = min(image_data['nums'])
        image_data['min'] = range_min
        image_data['max'] = range_max
        logger.debug('Created metadata store')
        
        # check the size of the batch
        if len(images) != BATCH_SIZE:
            logger.warning('Recieved {} frames when {} were expected. Skipping batch!'.format(len(images), BATCH_SIZE))
            return self.noop(image_data, image_processer.INCORRECT_NUM_IMAGES)

        # attempt to open the images
        image_data = { 'nums' : [], 'rasters' : [] }
        for image in images:
            num = self.get_filename_num(image)
            raster = cv2.imread(image, cv2.IMREAD_UNCHANGED)

            if raster is None:
                logger.warning('Could not open {}. Skipping batch!'.format(image))
                return self.noop(image_data, image_processer.COULD_NOT_READ_IMAGE)
            
            image_data['rasters'].append(raster)
        logger.debug('Loaded images')
                
        # try to stitch the frames together        
        stitched_image = self.film_stitcther.stitch(image_data['rasters'])
        if stitched_image is None:
            logger.warning('Could not stitch film strips together. Skipping batch!')
            return self.noop(image_data, image_processer.COULD_NOT_STITCH_FILM)
        logger.debug('Finished stitching image')

        # rotate the film to the correct orientation
        oriented_image = self.ocr_reader.orient(stitched_image)
        cv2.imwrite('/home/ubuntu/test.png', oriented_image)
        cv2.waitKey()
        if oriented_image is None:
            logger.warning('Could not determine the correct orientation of the film. Skipping batch!')
            return self.noop(image_data, image_processer.COULD_NOT_ORIENT_FILM)
        logger.debug('Finished orienting image')


        # perform OCR
        text_detections = 1
        #text_detections = self.ocr_reader.find_text(oriented_image)
        if text_detections is None:
            logger.warning('Could not find text on the stitched film strip. Skipping batch!')
            return self.noop(image_data, image_processer.COULD_NOT_FIND_TEXT)
        logger.debug('Finished detecting text in the image')

        # check that the recognized text is sensible
        # TODO(jremmons) write code to verify the detected text
        
        # dump output to tif and annotated jpeg file
        
        # report the csv-formated line(s) that should be logged
        
        cv2.waitKey()
        return ''
        
def main(args):

    logger.info('Using {} worker(s)'.format(args.num_workers))
    #pool = mp.Pool(args.num_workers)

    logger.debug('Checking if {} exists'.format(args.output_dir))
    try:
        os.makedirs(args.output_dir)
    except OSError as e:
        if e.errno != errno.EEXIST:
            logger.error('{} already exists!'.format(args.output_dir))
            return 
        else:
            raise e
    
    args.output_csv = os.path.join(args.output_dir, RESULTS_FILENAME)
        
    logger.debug('Checking if {} exists'.format(args.output_csv))
    with open(args.output_csv, 'x') as f:
        f.write('\n')
        
    logger.info('Initialization completed')

    logger.debug('Preparing macro batches for processing')    
    if args.flush_interval is None:
        macro_batches = [args.images]
    else:
        macro_batch_size = BATCH_SIZE * args.flush_interval * args.num_workers
        macro_batches = []
        for i in range(0, len(args.images), macro_batch_size):
            macro_batches.append(args.images[i:i+macro_batch_size])
            
    logger.info('Batches preapred (begin processing)')
            
    logger.debug('Processing data in %d batch(es)' % len(macro_batches))
            
    logger.debug('Begin processing batch(es)')
    for macro_batch in macro_batches:
        batches = []
        for i in range(0, len(macro_batch), BATCH_SIZE):
            batches.append(macro_batch[i:i+BATCH_SIZE])

        CSVrows = itertools.chain.from_iterable(
            #pool.map(image_processer(), batches)
            map(image_processer(), [batches[0]])
        )
        
        with open(args.output_csv, 'a') as f:
            f.write('\n'.join(CSVrows))
        logger.debug('Completed a macro batch')

            
    logger.debug('Finished processing batch(es)')

    logger.info('Done!')
        
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Perform OCR on radiometric data from Antarctic glaciers.')

    parser.add_argument('--parallel',
                        dest='num_workers',
                        metavar='num_workers',
                        type=int,
                        help='num worker processes to use (default: num cores on machine)',
                        default=os.cpu_count())

    parser.add_argument('--flush',
                        dest='flush_interval',
                        metavar='flush_interval',
                        type=int,
                        help='number of batches to process before flushing results to output.csv (default: flush every batch)',
                        default=1)

    parser.add_argument('-o',
                        dest='output_dir',
                        metavar='output_dir',
                        type=str,
                        help='the directory to output processed images and CSV results')

    parser.add_argument(dest='images',
                        metavar='image',
                        type=str,
                        nargs='+',
                        help='images to process (NOTE: processed in the order they appear)')

    args = parser.parse_args()
        
    main(args)
