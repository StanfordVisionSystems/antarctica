#!/usr/bin/env python3 

import argparse
import cv2
import errno
import itertools
import git
import os
import simplejson
import datetime

import pathos.multiprocessing as mp
import numpy as np
import AntarcticaUtils as a

import logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# number of frames to stitch together
BATCH_SIZE = 25
RESULTS_FILENAME = 'results.csv'
RESULTS_IMAGE_DIRNAME = 'stitched_images'

assert(not git.Repo(search_parent_directories=True).is_dirty()) # GIT REPO IS DITRY!
CSV_COMMENT_LINES = ['creation_time: '+str(datetime.datetime.now()),
                     'code_version: ' + str(git.Repo(search_parent_directories=True).head.object.hexsha)]

OUTPUT_FORMAT = '{reel_num},{begin_image_num},{end_image_num},{horizontal_flip},{vertical_flip},{high_res_filename},{low_res_filename},{status},{date},{time1},{time2},{setting},{flight},{cbd1},{cbd2},{cbd1_fractional},{cbd2_fractional},{num_additional_columns}'

OUTPUT_IMAGE_FILENAME_FORMAT = '{}_{}_{}-reel_image_image.{}'
OUTPUT_SMALL_IMAGE_FACTOR = 1/3.16227766017 # 1/sqrt(10)

class image_processer:

    SUCCESS = '0_success'
    COULD_NOT_PARSE_IMAGE_FILENAME = '1_malformed_image_filename'
    INCORRECT_NUM_IMAGES = '2_not_enough_images_in_batch'
    COULD_NOT_READ_IMAGE = '3_image_read_error'
    COULD_NOT_STITCH_FILM = '4_image_stitch_error'
    COULD_NOT_ORIENT_FILM = '5_image_orientation_error'
    COULD_NOT_FIND_TEXT = '6_image_find_text_error'
    COULD_NOT_PARSE_TEXT = '7_image_parse_text_error'
    COULD_NOT_WRITE_STITCHED_IMAGE = '8_could_not_write_stitched_image'
    
    def __init__(self, reel_num, output_dir):
        self.ocr_reader = a.BasicOCRReader()
        self.output_dir = output_dir
        self.reel_num = reel_num
        self.count = 0
        
    def get_filename_num(self, filename):
        return filename.split('_')[-1].split('.')[0]

    def noop(self, image_data, reason):
        logger.critical('FAILURE: {} {}'.format(image_data['min'], image_data['max']))
        logger.debug('performing noop for images because of: {}'.format(reason))

        image_names = None
        if reason == image_processer.COULD_NOT_PARSE_IMAGE_FILENAME:
            image_names = image_data
        else:
            image_names = image_data['images']
 
        d = {
            'reel_num' : self.reel_num,
            'begin_image_num' : image_data['min'],
            'end_image_num' : image_data['max'],
            'horizontal_flip' : '',
            'vertical_flip' : 'false',
            'high_res_filename' : '',
            'low_res_filename' : '',
            'status' : reason,
            'date' : '',
            'time1' : '',
            'time2' : '',
            'setting' : '',
            'flight' : '', 
            'cbd1' : '', 
            'cbd2' : '', 
            'cbd1_fractional' : '',
            'cbd2_fractional' : '',
            'num_additional_columns' : '0'
        }

        if reason not in [image_processer.COULD_NOT_PARSE_IMAGE_FILENAME, image_processer.INCORRECT_NUM_IMAGES, image_processer.COULD_NOT_READ_IMAGE]:
            im = image_data['try_oriented_image']

            d['horizontal_flip'] = image_data['horizontal_flip']
            d['vertical_flip'] = image_data['vertical_flip']
            d['num_additional_columns'] = len(image_data['text_detections'][0]) + len(image_data['text_detections'][1])
            
            if im is None:
                lines.append(OUTPUT_FORMAT.format(**d))
                
            tiff_filename = os.path.join(self.output_dir, RESULTS_IMAGE_DIRNAME, OUTPUT_IMAGE_FILENAME_FORMAT.format(self.reel_num, image_data['min'], image_data['max'], 'tiff'))
            jpg_filename = os.path.join(self.output_dir, RESULTS_IMAGE_DIRNAME, OUTPUT_IMAGE_FILENAME_FORMAT.format(self.reel_num, image_data['min'], image_data['max'], 'jpg'))
        
            ret = cv2.imwrite(tiff_filename, im)
            if not ret:
                logger.debug('Could not process {}. Adding partial noop line'.format(image))
                lines.append(OUTPUT_FORMAT.format(**d))
        
            d['high_res_filename'] = tiff_filename

            oriented_image_labelled = a.BasicOCRReader.annotate_image_digits(im, image_data['text_detections'][0]+image_data['text_detections'][1], logger)
            
            im_small = cv2.resize(oriented_image_labelled, None, fx=OUTPUT_SMALL_IMAGE_FACTOR, fy=OUTPUT_SMALL_IMAGE_FACTOR, interpolation = cv2.INTER_CUBIC)
            im_small = (im_small * (255 / 65535.0)).astype(np.uint8)
            ret = cv2.imwrite(jpg_filename, im_small)
        
            if not ret:
                logger.debug('Could not process {}. Adding partial noop line'.format(image))
                lines.append(OUTPUT_FORMAT.format(**d))

            d['low_res_filename'] = jpg_filename

            line = OUTPUT_FORMAT.format(**d)
            dumps = lambda x : ',"' + simplejson.dumps(x,sort_keys=True).replace('"', "'").strip() + '"'
            for char_detection in image_data['text_detections'][0] + image_data['text_detections'][1]:
                del char_detection['x1']
                del char_detection['x2']
                del char_detection['y1']
                del char_detection['y2']
                del char_detection['segment']
                line += dumps(char_detection)
            
            return [line]

        else:

            lines = []
            for image in image_names:
                try:
                    num = self.get_filename_num(image)
                except:
                    logger.critical('Could not parse the image number from the filename {}; using global counter'.format(image))
                    num = str(self.count)
                    self.count += 1

                d = {
                    'reel_num' : self.reel_num,
                    'begin_image_num' : num,
                    'end_image_num' : num,
                    'horizontal_flip' : 'false',
                    'vertical_flip' : 'false',
                    'high_res_filename' : '',
                    'low_res_filename' : '',
                    'status' : reason,
                    'date' : '',
                    'time1' : '',
                    'time2' : '',
                    'setting' : '',
                    'flight' : '', 
                    'cbd1' : '', 
                    'cbd2' : '', 
                    'cbd1_fractional' : '',
                    'cbd2_fractional' : '',
                    'num_additional_columns' : '0', 
                }
            
                im = cv2.imread(image)
                if im is None:
                    lines.append(OUTPUT_FORMAT.format(**d))
                    continue
                
                tiff_filename = os.path.join(self.output_dir, RESULTS_IMAGE_DIRNAME, OUTPUT_IMAGE_FILENAME_FORMAT.format(self.reel_num, num, num, 'tiff'))
                jpg_filename = os.path.join(self.output_dir, RESULTS_IMAGE_DIRNAME, OUTPUT_IMAGE_FILENAME_FORMAT.format(self.reel_num, num, num, 'jpg'))

                ret = cv2.imwrite(tiff_filename, im)
                if not ret:
                    logger.debug('Could not process {}. Adding partial noop line'.format(image))
                    lines.append(OUTPUT_FORMAT.format(**d))
                    continue
            
                d['high_res_filename'] = tiff_filename
            
                im_small = cv2.resize(im, None, fx=OUTPUT_SMALL_IMAGE_FACTOR, fy=OUTPUT_SMALL_IMAGE_FACTOR, interpolation = cv2.INTER_CUBIC)
                im_small = (im_small * (255 / 65535.0)).astype(np.uint8)
                ret = cv2.imwrite(jpg_filename, im_small)

                if not ret:
                    logger.debug('Could not process {}. Adding partial noop line'.format(image))
                    lines.append(OUTPUT_FORMAT.format(**d))
                    continue

                d['low_res_filename'] = jpg_filename
                
                lines.append(OUTPUT_FORMAT.format(**d))
                
                logger.debug('Added noop line for image {}'.format(image))

            return lines
        
    def __call__(self, images):

        logger.debug('processing images in reel {}'.format(self.reel_num))

        image_data = {'images' : images, 'nums' : [], 'min' : None, 'max' : None, 'rasters' : []}
        try:
            for image in images:
                num = self.get_filename_num(image)
                image_data['nums'].append(num)
        except:
            logger.error('input filename is malformed; could not parse image number')
            return self.noop(images, image_processer.COULD_NOT_PARSE_IMAGE_FILENAME)

        range_min = min(image_data['nums'])
        range_max = max(image_data['nums'])
        image_data['min'] = range_min
        image_data['max'] = range_max
        logger.debug('processing images {} to {}'.format(image_data['min'], image_data['max']))

        logger.debug('Created metadata store')
        
        # check the size of the batch
        if len(images) != BATCH_SIZE:
            logger.warning('Recieved {} frames when {} were expected. Skipping batch!'.format(len(images), BATCH_SIZE))
            return self.noop(image_data, image_processer.INCORRECT_NUM_IMAGES)

        ########################################################################
        # attempt to open the images
        ########################################################################
        image_data['nums'] = []
        image_data['rasters'] = []
        for image in images:
            num = self.get_filename_num(image)
            raster = cv2.imread(image, cv2.IMREAD_UNCHANGED)

            if raster is None:
                logger.warning('Could not open {}. Skipping batch!'.format(image))
                return self.noop(image_data, image_processer.COULD_NOT_READ_IMAGE)
            
            image_data['rasters'].append(raster)
        logger.debug('Loaded images')
                
        ########################################################################
        # try to stitch the frames together
        ########################################################################
        try:
            stitched_image = a.BasicFilmstripStitcher.stitch(image_data['rasters'], logger)
        except:
            stitched_image = None
        if stitched_image is None:
            logger.warning('Could not stitch film strips together. Skipping batch!')
            return self.noop(image_data, image_processer.COULD_NOT_STITCH_FILM)

        logger.debug('Finished stitching image')
        
        ########################################################################
        # rotate the film to the correct orientation
        ########################################################################
        try:
            oriented_image = self.ocr_reader.orient(stitched_image, logger)
        except:
            oriented_image = None
        if oriented_image is None:
            logger.warning('Could not determine the correct orientation of the film. Skipping batch!')
            return self.noop(image_data, image_processer.COULD_NOT_ORIENT_FILM)
        image_data['oriented_image'] = oriented_image
        logger.debug('Finished orienting image')

        ########################################################################
        # perform OCR
        ########################################################################
        metadata = None
        number_groups = None
        end = 0
        max_detections = 0
        horizontal_flip = 'false'
        vertical_flip = 'false'
        image_data['horizontal_flip'] = horizontal_flip
        image_data['vertical_flip'] = vertical_flip
        image_data['try_oriented_image'] = oriented_image
        image_data['text_detections'] = ([], [])
        for orientation in [(False, False), (True, True), (True, False), (False, True)]:
            logger.debug('trying orientation horizontal:{} vertical:{}'.format(orientation[0], orientation[1]))
            end += 1
            
            try_image_orientation = oriented_image.copy()
            if orientation[1]:
                try_image_orientation = cv2.flip(try_image_orientation, 0)
                vertical_flip = 'true'
            if orientation[0]:
                try_image_orientation = cv2.flip(try_image_orientation, 1)
                horizontal_flip = 'true'
                
            try:
                text_detections = self.ocr_reader.find_text(try_image_orientation, logger)
            except:
                text_detections = None
            if text_detections is None:
                if end < 4:
                    logger.warning('Could not stitched film strip. Trying a new orientation')
                    continue

                logger.warning('Could not find text on the stitched film strip. Skipping batch!')
                return self.noop(image_data, image_processer.COULD_NOT_FIND_TEXT)

            logger.debug('Finished detecting text in the image')

            if len(text_detections[0]) + len(text_detections[1]) > max_detections:
                logger.debug('new best detection')
                max_detections = len(text_detections[0]) + len(text_detections[1])

                image_data['horizontal_flip'] = horizontal_flip
                image_data['vertical_flip'] = vertical_flip
                image_data['try_oriented_image'] = try_image_orientation
                image_data['text_detections'] = text_detections
            
            ########################################################################
            # check that the recognized text is sensible and interpret it
            ########################################################################
            try:
                interpretation = self.ocr_reader._interpret_text(text_detections, try_image_orientation.shape, logger)
            except:
                interpretation = None
            if interpretation is None:
                if end < 4:
                    logger.warning('Could not interpret text on the stitched film strip. Trying a new orientation')
                    continue

                logger.warning('Could not interpret text on the stitched film strip. Skipping batch!')
                return self.noop(image_data, image_processer.COULD_NOT_PARSE_TEXT)
            
            metadata, number_groups = interpretation
            metadata['horizontal_flip'] = horizontal_flip
            metadata['vertical_flip'] = vertical_flip
            oriented_image = try_image_orientation
            if interpretation is not None:
                logger.debug('Finished interpretating text in the image')
                break
            
        ########################################################################
        # dump output to tiff and annotated jpeg file
        ########################################################################
        tiff_filename = os.path.join(self.output_dir, RESULTS_IMAGE_DIRNAME, OUTPUT_IMAGE_FILENAME_FORMAT.format(self.reel_num, image_data['min'], image_data['max'], 'tiff'))
        jpg_filename = os.path.join(self.output_dir, RESULTS_IMAGE_DIRNAME, OUTPUT_IMAGE_FILENAME_FORMAT.format(self.reel_num, image_data['min'], image_data['max'], 'jpg'))

        ret = cv2.imwrite(tiff_filename, oriented_image)
        if not ret:
            logger.warning('Could not write tiff output to disk (ret={}); skipping batch!'.format(ret))
            return self.noop(image_data, image_processer.COULD_NOT_WRITE_STITCHED_IMAGE)

        oriented_image_labelled = a.BasicOCRReader.annotate_image(oriented_image, number_groups, logger)
        oriented_image_small = cv2.resize(oriented_image_labelled, None, fx=OUTPUT_SMALL_IMAGE_FACTOR, fy=OUTPUT_SMALL_IMAGE_FACTOR, interpolation = cv2.INTER_CUBIC)
        oriented_image_small = (oriented_image_small * (255 / 65535.0)).astype(np.uint8)
        ret = cv2.imwrite(jpg_filename, oriented_image_small)
        if not ret:
            logger.warning('Could not write jpg output to disk (ret={}); skipping batch!'.format(ret))
            return self.noop(image_data, image_processer.COULD_NOT_WRITE_STITCHED_IMAGE)

        logger.debug('Finished writing the stitched image to disk')
        
        # report the csv-formated line(s) that should be logged
        metadata['reel_num'] = self.reel_num
        metadata['begin_image_num'] = image_data['min']
        metadata['end_image_num'] = image_data['max']

        metadata['high_res_filename'] = tiff_filename
        metadata['low_res_filename'] = jpg_filename

        metadata['status'] = image_processer.SUCCESS

        metadata['num_additional_columns'] = len(number_groups) + len(text_detections[0]) + len(text_detections[1])
        line = OUTPUT_FORMAT.format(**metadata)

        # add supplementary information to the line (text detections and positions)
        dumps = lambda x : ',"' + simplejson.dumps(x,sort_keys=True).replace('"', "'").strip() + '"'
        for number_group in number_groups:
            line += dumps(number_group)

        for char_detection in text_detections[0] + text_detections[1]:
            del char_detection['x1']
            del char_detection['x2']
            del char_detection['y1']
            del char_detection['y2']
            del char_detection['segment']
            line += dumps(char_detection)

        logger.critical('SUCCESS: {} {}'.format(image_data['min'], image_data['max']))
            
        return [line]
            
def main(args):

    logger.info('Using {} worker(s)'.format(args.num_workers))
    pool = mp.Pool(args.num_workers)

    logger.debug('Checking if {} exists'.format(args.output_dir))
    try:
        os.makedirs(args.output_dir)
    except OSError as e:
        if e.errno != errno.EEXIST:
            logger.error('{} already exists!'.format(args.output_dir))
            return 
        else:
            raise e

    args.output_csv = os.path.join(args.output_dir, RESULTS_FILENAME)
    args.output_image_dir = os.path.join(args.output_dir, RESULTS_IMAGE_DIRNAME)
    os.makedirs(args.output_image_dir)
        
    logger.debug('Checking if {} exists'.format(args.output_csv))
    with open(args.output_csv, 'x') as f:
        for line in CSV_COMMENT_LINES:
            f.write('# ' + line.strip() + '\n')

        header = OUTPUT_FORMAT.replace('{', '').replace('}', '').strip()
        f.write(header+'\n')
        
    logger.info('Initialization completed')
    logger.debug('Preparing macro batches for processing')    
    if args.flush_interval is -1:
        macro_batches = [args.images]
    elif args.flush_interval is 0:
        logger.error('0 is not a valid flush interval (use -1 to disable flushing)')
    else:
        macro_batch_size = BATCH_SIZE * args.flush_interval * args.num_workers
        macro_batches = []
        for i in range(0, len(args.images), macro_batch_size):
            macro_batches.append(args.images[i:i+macro_batch_size])
            
    logger.info('Batches preapred (begin processing)')
    logger.debug('Processing data in %d batch(es)' % len(macro_batches))
    logger.debug('Begin processing batch(es)')
    for macro_batch in macro_batches:
        batches = []
        for i in range(0, len(macro_batch), BATCH_SIZE):
            batches.append(macro_batch[i:i+BATCH_SIZE])

        CSVrows = itertools.chain.from_iterable(
            pool.map(image_processer(args.reel_num, args.output_dir), batches)
        )
        
        with open(args.output_csv, 'a') as f:
            f.write('\n'.join(CSVrows)+'\n')

        logger.debug('Completed a macro batch')

    pool.close()
    pool.join()
    logger.debug('Finished processing batch(es)')
    logger.info('Done!')
        
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Perform OCR on radiometric data from Antarctic glaciers.')

    parser.add_argument('--parallel',
                        dest='num_workers',
                        metavar='num_workers',
                        type=int,
                        help='num worker processes to use (default: num cores on machine)',
                        default=os.cpu_count())

    parser.add_argument('--reel',
                        dest='reel_num',
                        metavar='reel_num',
                        type=str,
                        help='the reel number to use in the csv output')

    parser.add_argument('--flush',
                        dest='flush_interval',
                        metavar='flush_interval',
                        type=int,
                        help='number of batches to process before flushing results to output.csv (default: flush every batch); to disable flushing pass -1',
                        default=1)

    parser.add_argument('--output',
                        dest='output_dir',
                        metavar='output_dir',
                        type=str,
                        help='the directory to output processed images and CSV results')

    parser.add_argument(dest='images',
                        metavar='image',
                        type=str,
                        nargs='+',
                        help='images to process (NOTE: processed in the order they appear)')

    args = parser.parse_args()
        
    main(args)
