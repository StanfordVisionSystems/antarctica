#!/usr/bin/env python3 

import argparse
import cv2
import errno
import itertools
import git
import os
import datetime


import pathos.multiprocessing as mp
import AntarcticaUtils as a

import logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# number of frames to stitch together
BATCH_SIZE = 25
RESULTS_FILENAME = 'results.csv'

assert(not git.Repo(search_parent_directories=True).is_dirty())
CSV_COMMENT_LINES = ['creation_time: '+str(datetime.datetime.now()),
                     'code_version: ' + str(git.Repo(search_parent_directories=True).head.object.hexsha)]

OUTPUT_FORMAT = '{reel_num},{begin_image_num},{end_image_num},{high_res_filename},{low_res_filename},{status},{date},{time1},{time2},{setting},{flight},{cbd1},{cbd2},{num_additional_columns}'

class image_processer:

    SUCCESS = '0_success'
    INCORRECT_NUM_IMAGES = '1_not_enough_images_in_batch'
    COULD_NOT_READ_IMAGE = '2_image_read_error'
    COULD_NOT_STITCH_FILM = '3_image_stitch_error'
    COULD_NOT_ORIENT_FILM = '4_image_orientation_error'
    COULD_NOT_FIND_TEXT = '5_image_find_text_error'
    COULD_PARSE_TEXT = '6_image_parse_text_error'
    
    def __init__(self):
        self.ocr_reader = a.BasicOCRReader()
        
    def get_filename_num(self, filename):
        return filename.split('_')[-1].split('.')[0]

    def noop(self, image_data, reason):
        # TODO(jremmons) write out image files
        # log the error in the CSV file
        return ''
        
    def __call__(self, images):

        image_data = {'nums' : [], 'min' : None, 'max' : None, 'rasters' : []}
        for image in images:
            num = self.get_filename_num(image)
            image_data['nums'].append(num)

        range_min = min(image_data['nums'])
        range_max = min(image_data['nums'])
        image_data['min'] = range_min
        image_data['max'] = range_max
        logger.debug('Created metadata store')
        
        # check the size of the batch
        if len(images) != BATCH_SIZE:
            logger.warning('Recieved {} frames when {} were expected. Skipping batch!'.format(len(images), BATCH_SIZE))
            return self.noop(image_data, image_processer.INCORRECT_NUM_IMAGES)

        # attempt to open the images
        image_data = { 'nums' : [], 'rasters' : [] }
        for image in images:
            num = self.get_filename_num(image)
            raster = cv2.imread(image, cv2.IMREAD_UNCHANGED)

            if raster is None:
                logger.warning('Could not open {}. Skipping batch!'.format(image))
                return self.noop(image_data, image_processer.COULD_NOT_READ_IMAGE)
            
            image_data['rasters'].append(raster)
        logger.debug('Loaded images')
                
        # try to stitch the frames together        
        stitched_image = a.BasicFilmstripStitcher.stitch(image_data['rasters'], logger)
        if stitched_image is None:
            logger.warning('Could not stitch film strips together. Skipping batch!')
            return self.noop(image_data, image_processer.COULD_NOT_STITCH_FILM)
        logger.debug('Finished stitching image')

        # rotate the film to the correct orientation
        oriented_image = self.ocr_reader.orient(stitched_image, logger)
        if oriented_image is None:
            logger.warning('Could not determine the correct orientation of the film. Skipping batch!')
            return self.noop(image_data, image_processer.COULD_NOT_ORIENT_FILM)
        logger.debug('Finished orienting image')

        # perform OCR
        text_detections = self.ocr_reader.find_text(oriented_image, logger)
        if text_detections is None:
            logger.warning('Could not find text on the stitched film strip. Skipping batch!')
            return self.noop(image_data, image_processer.COULD_NOT_FIND_TEXT)
        logger.debug('Finished detecting text in the image')

        # check that the recognized text is sensible and interpret it
        metadata = self.ocr_reader._interpret_text(text_detections, oriented_image.shape, logger)
        if metadata is None:
            logger.warning('Could not interpret text on the stitched film strip. Skipping batch!')
            return self.noop(image_data, image_processer.COULD_NOT_FIND_TEXT)
        logger.debug('Finished interpretating text in the image')
        
        # dump output to tif and annotated jpeg file
        
        
        # report the csv-formated line(s) that should be logged
        metadata['reel_num'] = '2'
        metadata['begin_image_num'] = '10'
        metadata['end_image_num'] = '30'

        metadata['high_res_filename'] = 'blah.tif'
        metadata['low_res_filename'] = 'blah.jpg'

        metadata['status'] = image_processer.SUCCESS

        metadata['num_additional_columns'] = '1'
        line = OUTPUT_FORMAT.format(**metadata)

        # add supplementary information to the line (text detections and positions)
        line += "," + "\"{'type':'cbd','value':'123123','x1':12,'x2':24,'y1':32,'y2':54}\""        
        
        return [line]
            
def main(args):

    logger.info('Using {} worker(s)'.format(args.num_workers))
    pool = mp.Pool(args.num_workers)

    logger.debug('Checking if {} exists'.format(args.output_dir))
    try:
        os.makedirs(args.output_dir)
    except OSError as e:
        if e.errno != errno.EEXIST:
            logger.error('{} already exists!'.format(args.output_dir))
            return 
        else:
            raise e
    
    args.output_csv = os.path.join(args.output_dir, RESULTS_FILENAME)
        
    logger.debug('Checking if {} exists'.format(args.output_csv))
    with open(args.output_csv, 'x') as f:
        f.write('\n')
        
    logger.info('Initialization completed')
    logger.debug('Preparing macro batches for processing')    
    if args.flush_interval is None:
        macro_batches = [args.images]
    else:
        macro_batch_size = BATCH_SIZE * args.flush_interval * args.num_workers
        macro_batches = []
        for i in range(0, len(args.images), macro_batch_size):
            macro_batches.append(args.images[i:i+macro_batch_size])
            
    logger.info('Batches preapred (begin processing)')
    logger.debug('Processing data in %d batch(es)' % len(macro_batches))
    logger.debug('Begin processing batch(es)')
    for macro_batch in macro_batches:
        batches = []
        for i in range(0, len(macro_batch), BATCH_SIZE):
            batches.append(macro_batch[i:i+BATCH_SIZE])

        CSVrows = itertools.chain.from_iterable(
            pool.map(image_processer(), batches[0:2])
        )
        
        with open(args.output_csv, 'a') as f:
            for line in CSV_COMMENT_LINES:
                f.write('# ' + line.strip() + '\n')

            header = OUTPUT_FORMAT.replace('{', '').replace('}', '').strip()
            f.write(header+'\n')
            f.write('\n'.join(CSVrows))

        logger.debug('Completed a macro batch')
            
    logger.debug('Finished processing batch(es)')
    logger.info('Done!')
        
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Perform OCR on radiometric data from Antarctic glaciers.')

    parser.add_argument('--parallel',
                        dest='num_workers',
                        metavar='num_workers',
                        type=int,
                        help='num worker processes to use (default: num cores on machine)',
                        default=os.cpu_count())

    parser.add_argument('--flush',
                        dest='flush_interval',
                        metavar='flush_interval',
                        type=int,
                        help='number of batches to process before flushing results to output.csv (default: flush every batch)',
                        default=None)# TODO(jremmons) make flushing default

    parser.add_argument('-o',
                        dest='output_dir',
                        metavar='output_dir',
                        type=str,
                        help='the directory to output processed images and CSV results')

    parser.add_argument(dest='images',
                        metavar='image',
                        type=str,
                        nargs='+',
                        help='images to process (NOTE: processed in the order they appear)')

    args = parser.parse_args()
        
    main(args)
