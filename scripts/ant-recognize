#!/usr/bin/python3

import cv2
import os
import sys
import numpy as np

pathname = os.path.dirname(sys.argv[0])
img = cv2.imread(str(sys.argv[1]))
vis = img.copy()

# Extract channels to be processed individually
channels = cv2.text.computeNMChannels(img)
# Append negative channels to detect ER- (bright regions over dark background)
cn = len(channels)-1
for c in range(0,cn):
    channels.append((255-channels[c]))

for channel in channels:
    print(os.path.abspath('trained_classifierNM1.xml'))
    erc1 = cv2.text.loadClassifierNM1(os.path.abspath('trained_classifierNM1.xml'))
    er1 = cv2.text.createERFilterNM1(erc1,16,0.00015,0.13,0.2,True,0.1)

    erc2 = cv2.text.loadClassifierNM2(os.path.abspath('trained_classifierNM2.xml'))
    er2 = cv2.text.createERFilterNM2(erc2,0.5)

    regions = cv2.text.detectRegions(channel,er1,er2)

    rects = cv2.text.erGrouping(img,channel,[r.tolist() for r in regions])
    #rects = cv2.text.erGrouping(img,channel,[x.tolist() for x in regions], cv2.text.ERGROUPING_ORIENTATION_ANY,'../../GSoC2014/opencv_contrib/modules/text/samples/trained_classifier_erGrouping.xml',0.5)

    #Visualization
    for r in range(0,np.shape(rects)[0]):
        rect = rects[r]
        cv2.rectangle(vis, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (0, 0, 0), 2)
        cv2.rectangle(vis, (rect[0],rect[1]), (rect[0]+rect[2],rect[1]+rect[3]), (255, 255, 255), 1)
    

#Visualization
cv2.imshow("Text detection result", vis)
cv2.waitKey(0)
    
'''
import sys
import numpy as np
import pyocr
import pyocr.builders
from PIL import Image

tool = pyocr.get_available_tools()[0]
print(tool.get_name())

word_boxes = tool.image_to_string(
        Image.open(sys.argv[1]),
        lang="letsgodigital",
        builder=pyocr.tesseract.DigitBuilder()
    )

print( word_boxes[:] )
'''
